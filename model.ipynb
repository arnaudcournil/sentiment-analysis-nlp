{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1cbd5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0416911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unsup(imdb_path = \"aclImdb\", max_=None):\n",
    "    texts = []\n",
    "\n",
    "    path = os.path.join(imdb_path, \"train/unsup\")\n",
    "    files = os.listdir(path)\n",
    "    if max_:\n",
    "        files = files[:max_]\n",
    "    for file in files:\n",
    "        with open(os.path.join(path, file), encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6dec458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reviews):\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    preprocess_reviews = []\n",
    "    for review in reviews:\n",
    "        text = re.sub(r'<[^>]+>', '', review)              # HTML tags\n",
    "        text = re.sub(r'\\b\\d+\\b', '', html.unescape(text))  # Entities + numbers\n",
    "        text = re.sub(r'\\s+', ' ', re.sub(r'[\\W_]+', ' ', text)).strip()  # Symbols + trim\n",
    "        preprocess_reviews.append(text)\n",
    "\n",
    "    vectorizer.fit(preprocess_reviews)\n",
    "\n",
    "    return vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010d9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(imdb_path = \"aclImdb\", split=\"train\", max_per_class=None):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in ['pos', 'neg']:\n",
    "        path = os.path.join(imdb_path, split, label)\n",
    "        files = os.listdir(path)\n",
    "        if max_per_class:\n",
    "            files = files[:max_per_class]\n",
    "        for file in files:\n",
    "            with open(os.path.join(path, file), encoding='utf-8') as f:\n",
    "                texts.append(f.read())\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSimilaritiesModel:\n",
    "    def __init__(self, beta, V, R, b, theta, lambd=0.1, nu=0.1):\n",
    "        self.beta = beta\n",
    "        self.V = V\n",
    "        self.R = R\n",
    "        self.b = b\n",
    "        self.theta = theta\n",
    "        self.lambd = lambd\n",
    "        self.nu = nu\n",
    "\n",
    "    def compute_energy(self, w, theta, phi_w, b_w):\n",
    "        return -np.dot(theta, phi_w) - b_w\n",
    "\n",
    "    def compute_word_probabilities(self, theta, R, b):\n",
    "        energy = np.dot(R.T, theta) + b\n",
    "        energy_max = np.max(energy)\n",
    "        log_probabilities = energy - (np.log(np.sum(np.exp(energy - energy_max))) + energy_max.squeeze())\n",
    "        return np.exp(log_probabilities)\n",
    "\n",
    "    def compute_document_probability(self, document):\n",
    "        word_indices = [list(self.V).index(word.lower()) for word in document.lower().split() if word.lower() in self.V]\n",
    "        word_probabilities = [self.compute_word_probabilities(self.theta, self.R[:, i], self.b[i])\n",
    "                              for i in word_indices]\n",
    "        return np.prod(word_probabilities)\n",
    "\n",
    "    def compute_log_likelihood(self, documents):\n",
    "        log_likelihood = 0.0\n",
    "        for document in documents:\n",
    "            log_likelihood += np.sum(np.log(self.compute_document_probability(document)))\n",
    "        return log_likelihood\n",
    "\n",
    "    def compute_regularization_term(self):\n",
    "        return self.nu * np.linalg.norm(self.R) ** 2\n",
    "\n",
    "    def compute_objective(self, documents):\n",
    "        log_likelihood = self.compute_log_likelihood(documents)\n",
    "        regularization_term = self.compute_regularization_term()\n",
    "        return log_likelihood + regularization_term\n",
    "\n",
    "    def optimize_parameters(self, documents, batch_size=32, max_iterations=100, learning_rate=0.1):\n",
    "        num_documents = len(documents)\n",
    "        num_batches = (num_documents + batch_size - 1) // batch_size\n",
    "\n",
    "        # Precompute word indices and probabilities for all documents\n",
    "        word_indices = [[list(self.V).index(word.lower()) for word in document.split() if word.lower() in self.V]\n",
    "                        for document in documents]\n",
    "        word_probabilities = [[self.compute_word_probabilities(self.theta, self.R[:, i], self.b[i])\n",
    "                                for i in indices] for indices in word_indices]\n",
    "\n",
    "        for iteration in range(max_iterations):\n",
    "            total_gradient_R = np.zeros((self.beta, len(self.V)))\n",
    "            total_gradient_b = np.zeros(len(self.V))\n",
    "            total_gradient_theta = np.zeros(self.beta)\n",
    "\n",
    "            for batch in range(num_batches):\n",
    "                start_idx = batch * batch_size\n",
    "                end_idx = min(start_idx + batch_size, num_documents)\n",
    "                batch_documents = documents[start_idx:end_idx]\n",
    "                batch_word_indices = word_indices[start_idx:end_idx]\n",
    "                batch_word_probabilities = word_probabilities[start_idx:end_idx]\n",
    "\n",
    "                gradient_R = np.zeros((self.beta, len(self.V)))\n",
    "                gradient_b = np.zeros(len(self.V))\n",
    "                gradient_theta = np.zeros(self.beta)\n",
    "\n",
    "                for doc_indices, doc_probs in zip(batch_word_indices, batch_word_probabilities):\n",
    "                    unique_doc_indices = np.unique(doc_indices)\n",
    "                    gradients = self.compute_gradients(unique_doc_indices, doc_probs)\n",
    "                    mask = np.zeros((self.beta, len(self.V)))\n",
    "                    mask[:, unique_doc_indices] = 1\n",
    "                    gradient_R += gradients[0] * mask\n",
    "                    gradient_b += gradients[1] * mask[0]\n",
    "                    gradient_theta += gradients[2]\n",
    "\n",
    "\n",
    "                total_gradient_R += gradient_R\n",
    "                total_gradient_b += gradient_b\n",
    "                total_gradient_theta += gradient_theta\n",
    "                print(\"batch: \",batch)\n",
    "\n",
    "            self.R -= learning_rate * (total_gradient_R + 2 * self.nu * self.R)\n",
    "            self.b -= learning_rate * total_gradient_b\n",
    "            self.theta -= learning_rate * (total_gradient_theta + 2 * self.lambd * self.theta)\n",
    "\n",
    "            objective = self.compute_objective(documents)\n",
    "            print(f\"Iteration {iteration+1}: Objective = {objective}\")\n",
    "\n",
    "    def compute_gradients(self, word_indices, word_probabilities):\n",
    "        gradient_R = np.zeros((self.beta, len(self.V)))\n",
    "        gradient_b = np.zeros(len(self.V))\n",
    "        \n",
    "\n",
    "        gradient_theta = np.zeros(self.beta)\n",
    "\n",
    "        for indices, prob_w in zip(word_indices, word_probabilities):\n",
    "            phi_w = self.R[:, indices]\n",
    "            b_w = self.b[indices]\n",
    "            gradient_R[:, indices] += (prob_w - 1) * self.theta\n",
    "            gradient_b[indices] += prob_w - 1\n",
    "            gradient_theta += prob_w * phi_w\n",
    "        return gradient_R, gradient_b, gradient_theta\n",
    "\n",
    "\n",
    "    def compute_document_similarity(self, document1, document2):\n",
    "        representation1 = self.compute_document_representation(document1)\n",
    "        representation2 = self.compute_document_representation(document2)\n",
    "        similarity = np.dot(representation1, representation2) / (np.linalg.norm(representation1) * np.linalg.norm(representation2))\n",
    "        return similarity\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "    def compute_document_representation(self, document):\n",
    "        word_indices = [list(self.V).index(word.lower()) for word in document.split() if word.lower() in self.V]\n",
    "        document_representation = np.zeros(self.beta)\n",
    "        for word_index in word_indices:\n",
    "            phi_w = self.R[:, word_index]\n",
    "            b_w = self.b[word_index]\n",
    "            word_probabilities = self.compute_word_probabilities(self.theta, phi_w, b_w)\n",
    "            document_representation += word_probabilities * phi_w\n",
    "        return document_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "981708eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review, model):\n",
    "    words = review.split()\n",
    "    probabilities = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_index = list(model.V).index(word)\n",
    "            phi_w = model.R[:, word_index]\n",
    "            b_w = model.b[word_index]\n",
    "            probability = model.compute_word_probabilities(model.theta, phi_w, b_w)\n",
    "            probabilities.append(probability)\n",
    "        except ValueError:\n",
    "            # Handle out-of-vocabulary words\n",
    "            probabilities.append(0.5)  # Assume equal probability for unknown words\n",
    "\n",
    "    average_probability = np.mean(probabilities)\n",
    "    if average_probability >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b1fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0\n",
      "batch:  1\n",
      "batch:  2\n",
      "batch:  3\n",
      "batch:  4\n",
      "batch:  5\n",
      "batch:  6\n",
      "batch:  7\n",
      "batch:  8\n",
      "batch:  9\n",
      "batch:  10\n",
      "batch:  11\n",
      "batch:  12\n",
      "batch:  13\n",
      "batch:  14\n",
      "batch:  15\n",
      "batch:  16\n",
      "batch:  17\n",
      "batch:  18\n",
      "batch:  19\n",
      "batch:  20\n",
      "batch:  21\n",
      "batch:  22\n",
      "batch:  23\n",
      "batch:  24\n",
      "batch:  25\n",
      "batch:  26\n",
      "batch:  27\n",
      "batch:  28\n",
      "batch:  29\n",
      "batch:  30\n",
      "batch:  31\n",
      "Iteration 1: Objective = 150611.9437886272\n",
      "batch:  0\n",
      "batch:  1\n",
      "batch:  2\n",
      "batch:  3\n",
      "batch:  4\n",
      "batch:  5\n",
      "batch:  6\n",
      "batch:  7\n",
      "batch:  8\n",
      "batch:  9\n",
      "batch:  10\n",
      "batch:  11\n",
      "batch:  12\n",
      "batch:  13\n",
      "batch:  14\n",
      "batch:  15\n",
      "batch:  16\n",
      "batch:  17\n",
      "batch:  18\n",
      "batch:  19\n",
      "batch:  20\n",
      "batch:  21\n",
      "batch:  22\n",
      "batch:  23\n",
      "batch:  24\n",
      "batch:  25\n",
      "batch:  26\n",
      "batch:  27\n",
      "batch:  28\n",
      "batch:  29\n",
      "batch:  30\n",
      "batch:  31\n",
      "Iteration 2: Objective = 144647.71081459738\n",
      "batch:  0\n",
      "batch:  1\n",
      "batch:  2\n",
      "batch:  3\n",
      "batch:  4\n",
      "batch:  5\n",
      "batch:  6\n",
      "batch:  7\n",
      "batch:  8\n",
      "batch:  9\n",
      "batch:  10\n",
      "batch:  11\n",
      "batch:  12\n",
      "batch:  13\n",
      "batch:  14\n",
      "batch:  15\n",
      "batch:  16\n",
      "batch:  17\n",
      "batch:  18\n",
      "batch:  19\n",
      "batch:  20\n",
      "batch:  21\n",
      "batch:  22\n",
      "batch:  23\n",
      "batch:  24\n",
      "batch:  25\n",
      "batch:  26\n",
      "batch:  27\n",
      "batch:  28\n",
      "batch:  29\n",
      "batch:  30\n",
      "batch:  31\n",
      "Iteration 3: Objective = 138919.66146633885\n"
     ]
    }
   ],
   "source": [
    "unsup = load_unsup(max_=1000)\n",
    "V = preprocess(unsup)\n",
    "beta = 100 # Dimension\n",
    "R = np.random.randn(beta, len(V))\n",
    "b = np.random.randn(len(V))\n",
    "theta = np.random.randn(beta)\n",
    "\n",
    "model = SemanticSimilaritiesModel(beta, V, R, b, theta)\n",
    "model.optimize_parameters(unsup, batch_size=32, max_iterations=3, learning_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b850a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[   0 1000]\n",
      " [   0 1000]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.50      1.00      0.67      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.25      0.50      0.33      2000\n",
      "weighted avg       0.25      0.50      0.33      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\courn\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\courn\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\courn\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "texts_test, labels_test = load_data(split=\"test\", max_per_class=1000)\n",
    "\n",
    "predictions = [predict_sentiment(text, model) for text in texts_test]\n",
    "\n",
    "accuracy = accuracy_score(labels_test, predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "confusion = confusion_matrix(labels_test, predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)\n",
    "\n",
    "classification = classification_report(labels_test, predictions)\n",
    "print('Classification Report:')\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de402b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4663831626886387"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_document_similarity(\"I like dogs\", \"I like cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "872aaa05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4771806209824731"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_document_similarity(\"I like dogs\", \"I love dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "176bf9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49200910253178176"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_document_similarity(\"I like dogs\", \"I hate dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b65c3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16513807225002863"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_document_similarity(\"I like dogs\", \"I 'm kevin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
